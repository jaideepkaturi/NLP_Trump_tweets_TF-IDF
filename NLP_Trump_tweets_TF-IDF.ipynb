{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here my objective is to develop a model that has an ability to predict how many retweets/likes a tweet from Trump will generate. The broad plan is to extract features from the tweets using an NLP approach and see if these features have any predective power. We will begin with a very simple approach called the TF-IDF (https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to build a benchmark model. See NLP_Trump_tweets_Topic_modelling notebook for a more thorough treatment of data collection, problem approach etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_colwidth', -1) #to show full tweets in the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1057254051254013953</td>\n",
       "      <td>2018-10-30 12:53:03</td>\n",
       "      <td>“If the Fed backs off and starts talking a little more Dovish, I think we’re going to be right back to our 2,800 to 2,900 target range that we’ve had for the S&amp;amp;P 500.” Scott Wren, Wells Fargo.</td>\n",
       "      <td>3854.0</td>\n",
       "      <td>13636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1057249169507803137</td>\n",
       "      <td>2018-10-30 12:33:39</td>\n",
       "      <td>The Stock Market is up massively since the Election, but is now taking a little pause - people want to see what happens with the Midterms. If you want your Stocks to go down, I strongly suggest voting Democrat. They like the Venezuela financial model, High Taxes &amp;amp; Open Borders!</td>\n",
       "      <td>7569.0</td>\n",
       "      <td>25503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1057247021919297536</td>\n",
       "      <td>2018-10-30 12:25:07</td>\n",
       "      <td>Congressman Kevin Brady of Texas is so popular in his District, and far beyond, that he doesn’t need any help - but I am giving it to him anyway. He is a great guy and the absolute “King” of Cutting Taxes. Highly respected by all, he loves his State &amp;amp; Country. Strong Endorsement!</td>\n",
       "      <td>4214.0</td>\n",
       "      <td>16375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1057243826899877889</td>\n",
       "      <td>2018-10-30 12:12:25</td>\n",
       "      <td>Congressman Andy Barr of Kentucky, who just had a great debate with his Nancy Pelosi run opponent, has been a winner for his State. Strong on Crime, the Border, Tax Cuts, Military, Vets and 2nd Amendment, we need Andy in D.C. He has my Strong Endorsement!</td>\n",
       "      <td>4532.0</td>\n",
       "      <td>17532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057110242541080577</td>\n",
       "      <td>2018-10-30 03:21:36</td>\n",
       "      <td>.@Erik_Paulsen, @Jason2CD, \\r\\n@JimHagedornMN and @PeteStauber love our Country and the Great State of Minnesota. They are winners and always get the job done. We need them all in Congress for #MAGA. Border, Military, Vets, 2nd A. Go Vote Minnesota. They have my Strong Endorsement!</td>\n",
       "      <td>6598.0</td>\n",
       "      <td>24168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1057254051254013953  2018-10-30 12:53:03   \n",
       "1  1057249169507803137  2018-10-30 12:33:39   \n",
       "2  1057247021919297536  2018-10-30 12:25:07   \n",
       "3  1057243826899877889  2018-10-30 12:12:25   \n",
       "4  1057110242541080577  2018-10-30 03:21:36   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                           text  \\\n",
       "0  “If the Fed backs off and starts talking a little more Dovish, I think we’re going to be right back to our 2,800 to 2,900 target range that we’ve had for the S&amp;P 500.” Scott Wren, Wells Fargo.                                                                                           \n",
       "1  The Stock Market is up massively since the Election, but is now taking a little pause - people want to see what happens with the Midterms. If you want your Stocks to go down, I strongly suggest voting Democrat. They like the Venezuela financial model, High Taxes &amp; Open Borders!     \n",
       "2  Congressman Kevin Brady of Texas is so popular in his District, and far beyond, that he doesn’t need any help - but I am giving it to him anyway. He is a great guy and the absolute “King” of Cutting Taxes. Highly respected by all, he loves his State &amp; Country. Strong Endorsement!   \n",
       "3  Congressman Andy Barr of Kentucky, who just had a great debate with his Nancy Pelosi run opponent, has been a winner for his State. Strong on Crime, the Border, Tax Cuts, Military, Vets and 2nd Amendment, we need Andy in D.C. He has my Strong Endorsement!                                \n",
       "4  .@Erik_Paulsen, @Jason2CD, \\r\\n@JimHagedornMN and @PeteStauber love our Country and the Great State of Minnesota. They are winners and always get the job done. We need them all in Congress for #MAGA. Border, Military, Vets, 2nd A. Go Vote Minnesota. They have my Strong Endorsement!     \n",
       "\n",
       "   retweets  favorites  \n",
       "0  3854.0    13636.0    \n",
       "1  7569.0    25503.0    \n",
       "2  4214.0    16375.0    \n",
       "3  4532.0    17532.0    \n",
       "4  6598.0    24168.0    "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load tweets data\n",
    "tweets_df = pd.read_csv('trump_tweets_6000.csv', parse_dates = True)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now vectorize every tweet using TF-IDF, use that as the feature matric and set number of retweets as the target. We will also try to quickly test out a Random Forest model and a couple of Linear Regression models out of the box from sklearn to see if they have any predictive power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#convert text to td-idf feature space. Retweets is target array. Test Random forest regressor as the predective model. \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import math\n",
    "text_list = list(tweets_df['text'])\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(text_list)\n",
    "X = vectorizer.transform(text_list)\n",
    "y = tweets_df['retweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root mean squared error on train data 4557.41\n",
      "root mean squared error on test data 9737.47\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = RandomForestRegressor(n_estimators = 100, oob_score = True, random_state = 0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_on_train = model.predict(X_train)\n",
    "rmse_train = math.sqrt(metrics.mean_squared_error(y_on_train, y_train))\n",
    "#predict for unseen test data\n",
    "y_pred = model.predict(X_test)\n",
    "rmse_test = math.sqrt(metrics.mean_squared_error(y_pred, y_test))\n",
    "print('root mean squared error on train data %.2f' % rmse_train)\n",
    "print('root mean squared error on test data %.2f' % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweets</th>\n",
       "      <th>retweets_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>10759.0</td>\n",
       "      <td>14981.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>23105.0</td>\n",
       "      <td>21075.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>12279.0</td>\n",
       "      <td>13020.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>31355.0</td>\n",
       "      <td>19151.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>23685.0</td>\n",
       "      <td>21426.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>11805.0</td>\n",
       "      <td>12064.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>18598.0</td>\n",
       "      <td>20271.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>13549.0</td>\n",
       "      <td>18202.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>21349.0</td>\n",
       "      <td>18971.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>16197.0</td>\n",
       "      <td>19709.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>11177.0</td>\n",
       "      <td>9933.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>31973.0</td>\n",
       "      <td>23294.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>18944.0</td>\n",
       "      <td>25779.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>17191.0</td>\n",
       "      <td>18150.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>12317.0</td>\n",
       "      <td>9765.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>6843.0</td>\n",
       "      <td>10852.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>10402.0</td>\n",
       "      <td>19797.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>21094.0</td>\n",
       "      <td>20160.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>22284.0</td>\n",
       "      <td>17737.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>17188.0</td>\n",
       "      <td>13948.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>5492.0</td>\n",
       "      <td>10510.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>19693.0</td>\n",
       "      <td>19531.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>14253.0</td>\n",
       "      <td>14213.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>7804.0</td>\n",
       "      <td>18413.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>18312.0</td>\n",
       "      <td>20467.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>16317.0</td>\n",
       "      <td>21956.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>32002.0</td>\n",
       "      <td>12998.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>30074.0</td>\n",
       "      <td>20703.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>20629.0</td>\n",
       "      <td>22607.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>12929.0</td>\n",
       "      <td>12022.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>9351.0</td>\n",
       "      <td>19039.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>13721.0</td>\n",
       "      <td>17249.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>12740.0</td>\n",
       "      <td>14965.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>20099.0</td>\n",
       "      <td>25207.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>7230.0</td>\n",
       "      <td>10074.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>12795.0</td>\n",
       "      <td>21855.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>20731.0</td>\n",
       "      <td>20303.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>12641.0</td>\n",
       "      <td>27831.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>9895.0</td>\n",
       "      <td>19589.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>28403.0</td>\n",
       "      <td>25916.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>17199.0</td>\n",
       "      <td>12895.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>26090.0</td>\n",
       "      <td>23563.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>8195.0</td>\n",
       "      <td>12199.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>15508.0</td>\n",
       "      <td>13810.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>9677.0</td>\n",
       "      <td>11150.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>31156.0</td>\n",
       "      <td>23207.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>10692.0</td>\n",
       "      <td>17971.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>9629.0</td>\n",
       "      <td>24763.326571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>13749.0</td>\n",
       "      <td>21228.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>11233.0</td>\n",
       "      <td>11852.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>11321.0</td>\n",
       "      <td>20348.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>16632.0</td>\n",
       "      <td>19414.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>30064.0</td>\n",
       "      <td>22973.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>24638.0</td>\n",
       "      <td>17576.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>29711.0</td>\n",
       "      <td>18571.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>13501.0</td>\n",
       "      <td>11297.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>19552.0</td>\n",
       "      <td>21765.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>9069.0</td>\n",
       "      <td>21497.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>33249.0</td>\n",
       "      <td>51811.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>23860.0</td>\n",
       "      <td>24169.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      retweets  retweets_predictions\n",
       "2650  10759.0   14981.760000        \n",
       "4020  23105.0   21075.040000        \n",
       "4930  12279.0   13020.610000        \n",
       "4920  31355.0   19151.410000        \n",
       "1700  23685.0   21426.210000        \n",
       "5328  11805.0   12064.180000        \n",
       "3468  18598.0   20271.240000        \n",
       "5034  13549.0   18202.080000        \n",
       "4316  21349.0   18971.490000        \n",
       "5384  16197.0   19709.130000        \n",
       "4535  11177.0   9933.230000         \n",
       "3810  31973.0   23294.380000        \n",
       "4405  18944.0   25779.250000        \n",
       "155   17191.0   18150.620000        \n",
       "190   12317.0   9765.810000         \n",
       "2984  6843.0    10852.420000        \n",
       "4086  10402.0   19797.880000        \n",
       "1857  21094.0   20160.830000        \n",
       "4919  22284.0   17737.840000        \n",
       "113   17188.0   13948.840000        \n",
       "4268  5492.0    10510.600000        \n",
       "1594  19693.0   19531.300000        \n",
       "2163  14253.0   14213.140000        \n",
       "2746  7804.0    18413.060000        \n",
       "3999  18312.0   20467.680000        \n",
       "2112  16317.0   21956.040000        \n",
       "3648  32002.0   12998.230000        \n",
       "4837  30074.0   20703.880000        \n",
       "1545  20629.0   22607.830000        \n",
       "5112  12929.0   12022.350000        \n",
       "...       ...            ...        \n",
       "4050  9351.0    19039.920000        \n",
       "4419  13721.0   17249.800000        \n",
       "677   12740.0   14965.400000        \n",
       "381   20099.0   25207.830000        \n",
       "2948  7230.0    10074.320000        \n",
       "3665  12795.0   21855.850000        \n",
       "1015  20731.0   20303.420000        \n",
       "666   12641.0   27831.730000        \n",
       "3401  9895.0    19589.610000        \n",
       "1420  28403.0   25916.740000        \n",
       "87    17199.0   12895.940000        \n",
       "1624  26090.0   23563.100000        \n",
       "4947  8195.0    12199.430000        \n",
       "3350  15508.0   13810.780000        \n",
       "2663  9677.0    11150.160000        \n",
       "1376  31156.0   23207.240000        \n",
       "4980  10692.0   17971.560000        \n",
       "3241  9629.0    24763.326571        \n",
       "1088  13749.0   21228.340000        \n",
       "1604  11233.0   11852.390000        \n",
       "4795  11321.0   20348.910000        \n",
       "3564  16632.0   19414.380000        \n",
       "4474  30064.0   22973.080000        \n",
       "4406  24638.0   17576.380000        \n",
       "3063  29711.0   18571.470000        \n",
       "3261  13501.0   11297.700000        \n",
       "2212  19552.0   21765.340000        \n",
       "4104  9069.0    21497.020000        \n",
       "2257  33249.0   51811.930000        \n",
       "783   23860.0   24169.700000        \n",
       "\n",
       "[1351 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_compare = pd.DataFrame(y_test)\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "y_compare['retweets_predictions'] = y_pred_series.values\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] alpha=0.0001, penalty=none ......................................\n",
      "[CV]  alpha=0.0001, penalty=none, score=-141245847.55650964, total=   0.2s\n",
      "[CV] alpha=0.0001, penalty=none ......................................\n",
      "[CV]  alpha=0.0001, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=none ......................................\n",
      "[CV]  alpha=0.0001, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=none ......................................\n",
      "[CV]  alpha=0.0001, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=none ......................................\n",
      "[CV]  alpha=0.0001, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l2, score=-141342575.21940422, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l2, score=-421175404.7426351, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l2, score=-185571054.03613493, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l2, score=-151750743.46178147, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l2, score=-279475920.11837405, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l1, score=-141245927.2694108, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l1, score=-421051315.3409619, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l1, score=-185460383.15472057, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l1, score=-151648290.59817988, total=   0.0s\n",
      "[CV] alpha=0.0001, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0001, penalty=l1, score=-279372699.7437105, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=none ......................................\n",
      "[CV]  alpha=0.0002, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=none ......................................\n",
      "[CV]  alpha=0.0002, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=none ......................................\n",
      "[CV]  alpha=0.0002, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=none ......................................\n",
      "[CV]  alpha=0.0002, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=none ......................................\n",
      "[CV]  alpha=0.0002, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l2, score=-141439273.32951522, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l2, score=-421299531.3092339, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l2, score=-185681767.941004, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] alpha=0.0002, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l2, score=-151853241.11341107, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l2, score=-279579186.092057, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l1, score=-141246006.98261854, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l1, score=-421051417.9991225, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l1, score=-185460475.21983835, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l1, score=-151648373.3012162, total=   0.0s\n",
      "[CV] alpha=0.0002, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0002, penalty=l1, score=-279372783.0677394, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=none ......................................\n",
      "[CV]  alpha=0.0005, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=none ......................................\n",
      "[CV]  alpha=0.0005, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=none ......................................\n",
      "[CV]  alpha=0.0005, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=none ......................................\n",
      "[CV]  alpha=0.0005, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=none ......................................\n",
      "[CV]  alpha=0.0005, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l2, score=-141729188.65826795, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l2, score=-421671516.9048757, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l2, score=-186013614.04755917, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l2, score=-152160505.0448486, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l2 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l2, score=-279888756.0938024, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l1, score=-141246246.12249988, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l1, score=-421051725.9739337, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l1, score=-185460751.41552177, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l1, score=-151648621.4106478, total=   0.0s\n",
      "[CV] alpha=0.0005, penalty=l1 ........................................\n",
      "[CV]  alpha=0.0005, penalty=l1, score=-279373033.0401466, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=none .......................................\n",
      "[CV]  alpha=0.001, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=none .......................................\n",
      "[CV]  alpha=0.001, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=none .......................................\n",
      "[CV]  alpha=0.001, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=none .......................................\n",
      "[CV]  alpha=0.001, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=none .......................................\n",
      "[CV]  alpha=0.001, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l2 .........................................\n",
      "[CV]  alpha=0.001, penalty=l2, score=-142211774.2112633, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l2 .........................................\n",
      "[CV]  alpha=0.001, penalty=l2, score=-422290172.46214074, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l2 .........................................\n",
      "[CV]  alpha=0.001, penalty=l2, score=-186565697.49153763, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l2 .........................................\n",
      "[CV]  alpha=0.001, penalty=l2, score=-152671839.09827456, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l2 .........................................\n",
      "[CV]  alpha=0.001, penalty=l2, score=-280403937.0654801, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l1 .........................................\n",
      "[CV]  alpha=0.001, penalty=l1, score=-141246644.6894871, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l1 .........................................\n",
      "[CV]  alpha=0.001, penalty=l1, score=-421052239.26638323, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l1 .........................................\n",
      "[CV]  alpha=0.001, penalty=l1, score=-185461211.74283683, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l1 .........................................\n",
      "[CV]  alpha=0.001, penalty=l1, score=-151649034.9273436, total=   0.0s\n",
      "[CV] alpha=0.001, penalty=l1 .........................................\n",
      "[CV]  alpha=0.001, penalty=l1, score=-279373449.6617557, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=none .......................................\n",
      "[CV]  alpha=0.002, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=none .......................................\n",
      "[CV]  alpha=0.002, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=none .......................................\n",
      "[CV]  alpha=0.002, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=none .......................................\n",
      "[CV]  alpha=0.002, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=none .......................................\n",
      "[CV]  alpha=0.002, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l2 .........................................\n",
      "[CV]  alpha=0.002, penalty=l2, score=-143174597.09442857, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l2 .........................................\n",
      "[CV]  alpha=0.002, penalty=l2, score=-423522482.77295685, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l2 .........................................\n",
      "[CV] . alpha=0.002, penalty=l2, score=-187666080.376756, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l2 .........................................\n",
      "[CV] . alpha=0.002, penalty=l2, score=-153691543.791882, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l2 .........................................\n",
      "[CV]  alpha=0.002, penalty=l2, score=-281431347.03620505, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l1 .........................................\n",
      "[CV]  alpha=0.002, penalty=l1, score=-141247441.8275138, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l1 .........................................\n",
      "[CV]  alpha=0.002, penalty=l1, score=-421053265.85281074, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l1 .........................................\n",
      "[CV]  alpha=0.002, penalty=l1, score=-185462132.40608656, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l1 .........................................\n",
      "[CV]  alpha=0.002, penalty=l1, score=-151649861.96276763, total=   0.0s\n",
      "[CV] alpha=0.002, penalty=l1 .........................................\n",
      "[CV]  alpha=0.002, penalty=l1, score=-279374282.90636355, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=none .......................................\n",
      "[CV]  alpha=0.005, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=none .......................................\n",
      "[CV]  alpha=0.005, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=none .......................................\n",
      "[CV]  alpha=0.005, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=none .......................................\n",
      "[CV]  alpha=0.005, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=none .......................................\n",
      "[CV]  alpha=0.005, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l2 .........................................\n",
      "[CV]  alpha=0.005, penalty=l2, score=-146042897.20971164, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l2 .........................................\n",
      "[CV]  alpha=0.005, penalty=l2, score=-427178496.5546267, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l2 .........................................\n",
      "[CV]  alpha=0.005, penalty=l2, score=-190935857.55362856, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.005, penalty=l2 .........................................\n",
      "[CV]  alpha=0.005, penalty=l2, score=-156725698.51500595, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l2 .........................................\n",
      "[CV]  alpha=0.005, penalty=l2, score=-284488679.4196815, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l1 .........................................\n",
      "[CV]  alpha=0.005, penalty=l1, score=-141249833.28012133, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l1 .........................................\n",
      "[CV]  alpha=0.005, penalty=l1, score=-421056345.6396067, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l1 .........................................\n",
      "[CV]  alpha=0.005, penalty=l1, score=-185464894.44519714, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l1 .........................................\n",
      "[CV]  alpha=0.005, penalty=l1, score=-151652343.09698883, total=   0.0s\n",
      "[CV] alpha=0.005, penalty=l1 .........................................\n",
      "[CV]  alpha=0.005, penalty=l1, score=-279376782.67916733, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=none ........................................\n",
      "[CV]  alpha=0.01, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=none ........................................\n",
      "[CV]  alpha=0.01, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=none ........................................\n",
      "[CV]  alpha=0.01, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=none ........................................\n",
      "[CV]  alpha=0.01, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=none ........................................\n",
      "[CV]  alpha=0.01, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l2 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l2, score=-150747962.8142494, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.01, penalty=l2, score=-433130283.33916897, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l2 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l2, score=-196274514.6272575, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l2 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l2, score=-161692048.8058218, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l2 ..........................................\n",
      "[CV] .. alpha=0.01, penalty=l2, score=-289493686.624019, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l1, score=-141253819.1432881, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l1, score=-421061478.7074169, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l1 ..........................................\n",
      "[CV]  alpha=0.01, penalty=l1, score=-185469496.93541923, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l1, score=-151656478.4441885, total=   0.0s\n",
      "[CV] alpha=0.01, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.01, penalty=l1, score=-279380946.3002969, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=none ........................................\n",
      "[CV]  alpha=0.02, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=none ........................................\n",
      "[CV]  alpha=0.02, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=none ........................................\n",
      "[CV]  alpha=0.02, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=none ........................................\n",
      "[CV]  alpha=0.02, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=none ........................................\n",
      "[CV]  alpha=0.02, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.02, penalty=l2, score=-159826944.68308157, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l2 ..........................................\n",
      "[CV] .. alpha=0.02, penalty=l2, score=-444475726.314102, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.02, penalty=l2, score=-206499820.43162113, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l2 ..........................................\n",
      "[CV] . alpha=0.02, penalty=l2, score=-171242477.9772531, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.02, penalty=l2, score=-299120446.17634517, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l1 ..........................................\n",
      "[CV]  alpha=0.02, penalty=l1, score=-141261791.14607194, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.02, penalty=l1, score=-421071745.2370483, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.02, penalty=l1, score=-185478702.3612023, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l1 ..........................................\n",
      "[CV]  alpha=0.02, penalty=l1, score=-151664748.91453075, total=   0.0s\n",
      "[CV] alpha=0.02, penalty=l1 ..........................................\n",
      "[CV] .. alpha=0.02, penalty=l1, score=-279389260.265155, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=none ........................................\n",
      "[CV]  alpha=0.05, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=none ........................................\n",
      "[CV]  alpha=0.05, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=none ........................................\n",
      "[CV]  alpha=0.05, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=none ........................................\n",
      "[CV]  alpha=0.05, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=none ........................................\n",
      "[CV]  alpha=0.05, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.05, penalty=l2, score=-183931658.24517813, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l2 ..........................................\n",
      "[CV] . alpha=0.05, penalty=l2, score=-473912521.9810421, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.05, penalty=l2, score=-233277148.85998732, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l2 ..........................................\n",
      "[CV]  alpha=0.05, penalty=l2, score=-196442193.85697028, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l2 ..........................................\n",
      "[CV] . alpha=0.05, penalty=l2, score=-324528712.0113316, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l1 ..........................................\n",
      "[CV]  alpha=0.05, penalty=l1, score=-141285702.90245634, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.05, penalty=l1, score=-421102556.3984601, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l1 ..........................................\n",
      "[CV] . alpha=0.05, penalty=l1, score=-185506317.8518029, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l1 ..........................................\n",
      "[CV]  alpha=0.05, penalty=l1, score=-151689566.31872144, total=   0.0s\n",
      "[CV] alpha=0.05, penalty=l1 ..........................................\n",
      "[CV]  alpha=0.05, penalty=l1, score=-279414201.66668385, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=none .........................................\n",
      "[CV]  alpha=0.1, penalty=none, score=-141245847.55650964, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=none .........................................\n",
      "[CV]  alpha=0.1, penalty=none, score=-421051212.68259895, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=none .........................................\n",
      "[CV]  alpha=0.1, penalty=none, score=-185460291.0896577, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=none .........................................\n",
      "[CV]  alpha=0.1, penalty=none, score=-151648207.89519772, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=none .........................................\n",
      "[CV]  alpha=0.1, penalty=none, score=-279372616.41973513, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l2 ...........................................\n",
      "[CV] . alpha=0.1, penalty=l2, score=-213733387.12835813, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l2 ...........................................\n",
      "[CV] .. alpha=0.1, penalty=l2, score=-509340670.1526175, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l2 ...........................................\n",
      "[CV] .. alpha=0.1, penalty=l2, score=-265878865.6418307, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l2 ...........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . alpha=0.1, penalty=l2, score=-227394145.45652053, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l2 ...........................................\n",
      "[CV] .. alpha=0.1, penalty=l2, score=-355738958.3908597, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l1 ...........................................\n",
      "[CV] .. alpha=0.1, penalty=l1, score=-141325557.8056674, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l1 ...........................................\n",
      "[CV] .. alpha=0.1, penalty=l1, score=-421153922.2576773, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l1 ...........................................\n",
      "[CV] . alpha=0.1, penalty=l1, score=-185552348.88538486, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l1 ...........................................\n",
      "[CV] . alpha=0.1, penalty=l1, score=-151730954.25400716, total=   0.0s\n",
      "[CV] alpha=0.1, penalty=l1 ...........................................\n",
      "[CV] .. alpha=0.1, penalty=l1, score=-279455781.4778735, total=   0.0s\n",
      "Time to train model: 1.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = SGDRegressor(loss='squared_loss', penalty='l2', random_state=42, max_iter=5)\n",
    "params = {'penalty':['none','l2','l1'],\n",
    "          'alpha':[1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 0.1]}\n",
    "gs = GridSearchCV(estimator=model,\n",
    "                  param_grid=params,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  n_jobs=1,\n",
    "                  cv=5,\n",
    "                  verbose=3)\n",
    "start = time.time()\n",
    "gs.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('Time to train model: %0.2fs' % (end -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_on_train = model.predict(X_train)\n",
    "rmse_train = math.sqrt(metrics.mean_squared_error(y_on_train, y_train))\n",
    "#predict for unseen test data\n",
    "y_pred = model.predict(X_test)\n",
    "rmse_test = math.sqrt(metrics.mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root mean squared error on train data 14660.63\n",
      "root mean squared error on test data 12501.21\n"
     ]
    }
   ],
   "source": [
    "print('root mean squared error on train data %.2f' % rmse_train)\n",
    "print('root mean squared error on test data %.2f' % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_on_train = model.predict(X_train)\n",
    "rmse_train = math.sqrt(metrics.mean_squared_error(y_on_train, y_train))\n",
    "#predict for unseen test data\n",
    "y_pred = model.predict(X_test)\n",
    "rmse_test = math.sqrt(metrics.mean_squared_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root mean squared error on train data 323.83\n",
      "root mean squared error on test data 34237.21\n"
     ]
    }
   ],
   "source": [
    "print('root mean squared error on train data %.2f' % rmse_train)\n",
    "print('root mean squared error on test data %.2f' % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329149.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tweets_df['retweets']) - min(tweets_df['retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5403.000000  \n",
       "mean     18671.330557 \n",
       "std      12300.082247 \n",
       "min      1091.000000  \n",
       "25%      11910.000000 \n",
       "50%      16523.000000 \n",
       "75%      22598.500000 \n",
       "max      330240.000000\n",
       "Name: retweets, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['retweets'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweets</th>\n",
       "      <th>retweets_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>10759.0</td>\n",
       "      <td>41283.990406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>23105.0</td>\n",
       "      <td>19871.727712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>12279.0</td>\n",
       "      <td>69855.849492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>31355.0</td>\n",
       "      <td>8611.572848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>23685.0</td>\n",
       "      <td>32636.855684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>11805.0</td>\n",
       "      <td>19931.284235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>18598.0</td>\n",
       "      <td>13966.698996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>13549.0</td>\n",
       "      <td>33186.851439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>21349.0</td>\n",
       "      <td>6466.134911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>16197.0</td>\n",
       "      <td>38722.566837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535</th>\n",
       "      <td>11177.0</td>\n",
       "      <td>21857.785924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>31973.0</td>\n",
       "      <td>59928.638887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>18944.0</td>\n",
       "      <td>62406.933284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>17191.0</td>\n",
       "      <td>14827.337026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>12317.0</td>\n",
       "      <td>31616.793739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>6843.0</td>\n",
       "      <td>-39529.760471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>10402.0</td>\n",
       "      <td>29512.220460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>21094.0</td>\n",
       "      <td>10150.339567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>22284.0</td>\n",
       "      <td>26968.310414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>17188.0</td>\n",
       "      <td>-1585.985926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>5492.0</td>\n",
       "      <td>-1215.737975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>19693.0</td>\n",
       "      <td>12820.245101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>14253.0</td>\n",
       "      <td>-5655.375039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>7804.0</td>\n",
       "      <td>-27262.998419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>18312.0</td>\n",
       "      <td>-4202.836847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>16317.0</td>\n",
       "      <td>-10685.016053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>32002.0</td>\n",
       "      <td>-6638.921899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>30074.0</td>\n",
       "      <td>-23817.892522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>20629.0</td>\n",
       "      <td>76973.498439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>12929.0</td>\n",
       "      <td>12411.200477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>9351.0</td>\n",
       "      <td>36979.896592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>13721.0</td>\n",
       "      <td>16815.772553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>12740.0</td>\n",
       "      <td>-136.968756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>20099.0</td>\n",
       "      <td>95371.868113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>7230.0</td>\n",
       "      <td>93644.366275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>12795.0</td>\n",
       "      <td>2269.307203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>20731.0</td>\n",
       "      <td>-33859.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>12641.0</td>\n",
       "      <td>33155.022090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>9895.0</td>\n",
       "      <td>-15622.882199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>28403.0</td>\n",
       "      <td>85198.709829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>17199.0</td>\n",
       "      <td>9091.728927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>26090.0</td>\n",
       "      <td>61661.866981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>8195.0</td>\n",
       "      <td>5138.628424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>15508.0</td>\n",
       "      <td>59567.549370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>9677.0</td>\n",
       "      <td>71367.259066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>31156.0</td>\n",
       "      <td>76160.808345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>10692.0</td>\n",
       "      <td>22321.031482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>9629.0</td>\n",
       "      <td>89044.481098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>13749.0</td>\n",
       "      <td>28683.162609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>11233.0</td>\n",
       "      <td>36759.458417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>11321.0</td>\n",
       "      <td>24149.108218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>16632.0</td>\n",
       "      <td>98199.289592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>30064.0</td>\n",
       "      <td>9763.906596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>24638.0</td>\n",
       "      <td>3518.263099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>29711.0</td>\n",
       "      <td>18028.307486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>13501.0</td>\n",
       "      <td>-27224.634430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>19552.0</td>\n",
       "      <td>2352.995257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>9069.0</td>\n",
       "      <td>62725.310789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>33249.0</td>\n",
       "      <td>57224.703209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>23860.0</td>\n",
       "      <td>44052.040031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      retweets  retweets_predictions\n",
       "2650  10759.0   41283.990406        \n",
       "4020  23105.0   19871.727712        \n",
       "4930  12279.0   69855.849492        \n",
       "4920  31355.0   8611.572848         \n",
       "1700  23685.0   32636.855684        \n",
       "5328  11805.0   19931.284235        \n",
       "3468  18598.0   13966.698996        \n",
       "5034  13549.0   33186.851439        \n",
       "4316  21349.0   6466.134911         \n",
       "5384  16197.0   38722.566837        \n",
       "4535  11177.0   21857.785924        \n",
       "3810  31973.0   59928.638887        \n",
       "4405  18944.0   62406.933284        \n",
       "155   17191.0   14827.337026        \n",
       "190   12317.0   31616.793739        \n",
       "2984  6843.0   -39529.760471        \n",
       "4086  10402.0   29512.220460        \n",
       "1857  21094.0   10150.339567        \n",
       "4919  22284.0   26968.310414        \n",
       "113   17188.0  -1585.985926         \n",
       "4268  5492.0   -1215.737975         \n",
       "1594  19693.0   12820.245101        \n",
       "2163  14253.0  -5655.375039         \n",
       "2746  7804.0   -27262.998419        \n",
       "3999  18312.0  -4202.836847         \n",
       "2112  16317.0  -10685.016053        \n",
       "3648  32002.0  -6638.921899         \n",
       "4837  30074.0  -23817.892522        \n",
       "1545  20629.0   76973.498439        \n",
       "5112  12929.0   12411.200477        \n",
       "...       ...            ...        \n",
       "4050  9351.0    36979.896592        \n",
       "4419  13721.0   16815.772553        \n",
       "677   12740.0  -136.968756          \n",
       "381   20099.0   95371.868113        \n",
       "2948  7230.0    93644.366275        \n",
       "3665  12795.0   2269.307203         \n",
       "1015  20731.0  -33859.005730        \n",
       "666   12641.0   33155.022090        \n",
       "3401  9895.0   -15622.882199        \n",
       "1420  28403.0   85198.709829        \n",
       "87    17199.0   9091.728927         \n",
       "1624  26090.0   61661.866981        \n",
       "4947  8195.0    5138.628424         \n",
       "3350  15508.0   59567.549370        \n",
       "2663  9677.0    71367.259066        \n",
       "1376  31156.0   76160.808345        \n",
       "4980  10692.0   22321.031482        \n",
       "3241  9629.0    89044.481098        \n",
       "1088  13749.0   28683.162609        \n",
       "1604  11233.0   36759.458417        \n",
       "4795  11321.0   24149.108218        \n",
       "3564  16632.0   98199.289592        \n",
       "4474  30064.0   9763.906596         \n",
       "4406  24638.0   3518.263099         \n",
       "3063  29711.0   18028.307486        \n",
       "3261  13501.0  -27224.634430        \n",
       "2212  19552.0   2352.995257         \n",
       "4104  9069.0    62725.310789        \n",
       "2257  33249.0   57224.703209        \n",
       "783   23860.0   44052.040031        \n",
       "\n",
       "[1351 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_compare = pd.DataFrame(y_test)\n",
    "y_pred_series = pd.Series(y_pred)\n",
    "y_compare['retweets_predictions'] = y_pred_series.values\n",
    "y_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Radom Forest regressor did surprisingly well, we can definitely extract much better features from these tweets. See the Topic Modelling notebook which tries to assign a topic vector for each tweet and use those as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
